{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# visualize\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# turn off pink warning boxes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# acquire\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************  connection url **********************************************\n",
    "\n",
    "# Create helper function to get the necessary connection url.\n",
    "def get_connection(db_name):\n",
    "    '''\n",
    "    This function uses my info from my env file to\n",
    "    create a connection url to access the Codeup db.\n",
    "    '''\n",
    "    from env import host, username, password\n",
    "    return f'mysql+pymysql://{username}:{password}@{host}/{db_name}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire data for the first time\n",
    "def get_new_telco_churn():\n",
    "    '''\n",
    "    This function reads in the telco_churn data from the Codeup db\n",
    "    and returns a pandas DataFrame with all columns and joined with other tables.\n",
    "    '''\n",
    "    sql_query = '''\n",
    "    SELECT * FROM customers\n",
    "    JOIN contract_types USING (contract_type_id)\n",
    "    JOIN internet_service_types USING (internet_service_type_id)\n",
    "    JOIN payment_types USING (payment_type_id)\n",
    "    '''\n",
    "    return pd.read_sql(sql_query, get_connection('telco_churn'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire data \n",
    "def get_telco_churn():\n",
    "    '''\n",
    "    This function reads in telco_churn data from Codeup database, writes data to\n",
    "    a csv file if a local file does not exist, and returns a df.\n",
    "    '''\n",
    "    if os.path.isfile('telco_churn.csv'):\n",
    "        \n",
    "        # If csv file exists, read in data from csv file.\n",
    "        df = pd.read_csv('telco_churn.csv', index_col=0)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Read fresh data from db into a DataFrame.\n",
    "        df = get_new_telco_churn()\n",
    "        \n",
    "        # Write DataFrame to a csv file.\n",
    "        df.to_csv('telco_churn.csv')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= get_telco_churn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the information before preparation process\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we cannot conver total_charges to float because there are ' '\n",
    "#df['total_charges'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#take a look. these are new customers \n",
    "df['total_charges'][df['total_charges']== ' '] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['total_charges'][df['total_charges']== ' '] + '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_charges'][df['total_charges']== ' '] = df['total_charges'][df['total_charges']== ' '] + '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to conver total_charges to float, I need will add '0' to ' '\n",
    "#df['total_charges'] = df['total_charges'] + '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to a float type\n",
    "df['total_charges'] = df['total_charges'].astype('float')\n",
    "df['total_charges'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the columns that have yes/no\n",
    "col_list = ['partner', 'dependents','phone_service',  #'tech_support', 'streaming_tv','streaming_movies'\n",
    "            'paperless_billing','churn' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all the values for these columns\n",
    "for col in col_list:\n",
    "    print(col)\n",
    "    print(df[col].value_counts())\n",
    "    print('__________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.churn == 'Yes').astype(int).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[col_list] == 'Yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[col_list] = (df[col_list] == 'Yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all the values for these columns to make sure it is correct\n",
    "for col in col_list:\n",
    "    print(col)\n",
    "    print(df[col].value_counts(dropna = False))\n",
    "    print('__________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.select_dtypes('object').columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(df.select_dtypes('object').columns)[1:]\n",
    "for col in col_list:\n",
    "    print(col)\n",
    "    print(df[col].value_counts())\n",
    "    print('__________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_list[2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dicttionary to change some columns to 0,1,2,\n",
    "var= {\n",
    "    'No':0,\n",
    "    'Yes':1,\n",
    "    'No internet service':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using .map to change the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_list[2:8]:\n",
    "      df[col]= df[col].map(var) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the changes\n",
    "df[col_list[2:8]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(df.select_dtypes('object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['multiple_lines'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'multiple_lines': {'No':0, 'Yes':1, 'No phone service': 2}}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['multiple_lines'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can create dummies for gender and contract_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating my function\n",
    "\n",
    "def clean_data(df, dummies):\n",
    "    '''\n",
    "    This function will drop any duplicate observations, \n",
    "    drop ['deck', 'embark_town', 'class'], fill missing embarked with 'Southampton'\n",
    "    and create dummy vars from sex and embarked. \n",
    "    '''\n",
    "\n",
    "    #clean data\n",
    "    # conver total_charges to float, first I need will add '0' to ' '\n",
    "    df['total_charges'] = df['total_charges'] + '0'\n",
    "    df['total_charges'] = df['total_charges'].astype('float')\n",
    "    \n",
    "    #converr all the columns that have yes/no to 0/1\n",
    "    col_list = ['partner', 'dependents','phone_service', 'tech_support', 'streaming_tv',\n",
    "            'streaming_movies', 'paperless_billing','churn' ]\n",
    "    df[col_list] = (df[col_list] == 'Yes').astype(int)\n",
    "    \n",
    "    \n",
    "    #create a dummy df\n",
    "    dummy_df = pd.get_dummies(df[dummies], drop_first=[True, True])\n",
    "    ## Concatenate the dummy_df dataframe above with the original df\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    # drop the columns that we already use to create dummy_df\n",
    "    df = df.drop(columns= dummies)\n",
    "    \n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
